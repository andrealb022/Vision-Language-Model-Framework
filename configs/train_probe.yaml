# Scegli il profilo di default da usare (puoi sovrascrivere da CLI: --profile single|multi)
profile: single

# ------------------- Configurazioni comuni -------------------
common:
  model:
    name: llava
    quantization: fp32
    dropout_p: 0.3
    deeper_head: false
    hidden_dim: 512
    backbone:
      freeze: true            # true = backbone congelata sempre
      unfreeze_last_k: 0      # >0 = sblocca ultimi k layer (valido solo se freeze=true)
      unfreeze_parts: all      # all | attn | mlp
      include_embeddings: true # true = include anche embeddings (valido solo se freeze=true)

  data:
    base_path: null
    batch_size: 128
    num_workers: 8

  train:
    epochs: 100
    lr: 0.0001                # LR teste di classificazione
    backbone_lr: 0.0001       # LR backbone (può essere uguale a lr)
    weight_decay: 0.0001
    patience: 6
    amp: true
    eval_every: 2
    scheduler:
      type: cosine_wr
      T_0: 10
      T_mult: 2

# ------------------- Configurazioni profilo single-task -------------------
single:
  task: emotion
  model:
    backbone:
      freeze: true            # true = backbone congelata sempre
      unfreeze_last_k: 0      # >0 = sblocca ultimi k layer (valido solo se freeze=true)

#------------------- Configurazioni profilo multi-task -------------------
multi:
  tasks: [gender, age, emotion]
  model:
    backbone:
      freeze: true             # true = backbone congelata
      unfreeze_last_k: 4       # >0 = sblocca ultimi k layer (valido solo se freeze=true)
      unfreeze_parts: all      # all | attn | mlp
      include_embeddings: true # true = include anche embeddings (valido solo se freeze=true)
  train:
    lr: 0.0001                 # LR teste di classificazione (e UW)
    backbone_lr: 0.00005       # LR backbone (può essere uguale a lr)

    uncertainty_weighting:
      enabled: true            # Abilita uncertainty weighting tra i task (opzionale)
      init_log_var: 0.0

    # Esempio: sampler con forza maggiore nel multi, mettere {} per disabilitare
    sampler: {}
      #type: weighted
      #beta: 1.0
      #replacement: true